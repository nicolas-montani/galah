\chapter{Introduction}
Recent cybersecurity literature has highlighted the paradigm shift in offensive and defensive strategies driven by the adoption of artificial intelligence, particularly the widespread availability of large language models (LLMs) This technological evolution has fundamentally altered the threat landscape, with both attackers and defenders leveraging AI capabilities to enhance their operations. The constantly evolving landscape of cybersecurity demands more sophisticated and adaptive defense strategies, as traditional static defense mechanisms prove increasingly insufficient against advanced persistent threats and zero-day vulnerabilities \cite{gizzarelli2024}.

The integration of Artificial Intelligence (AI) and Machine Learning (ML) represents one of the most significant emerging trends in cybersecurity, revolutionizing threat detection and response by enabling systems to analyze vast amounts of data at unprecedented speeds, identify patterns, and predict potential threats before they materialize. Moreover, the advent of generative AI, a subset of AI focused on creating new content or data, presents both opportunities and challenges in the cybersecurity landscape, opening new possibilities for both attackers and defenders \cite{gizzarelli2024}.

Honeypot technology has evolved similarly in response to these changes. AI-enhanced honeypots now offer improved credibility against sophisticated attackers \cite{christli2024}, enhanced threat actor analysis capabilities through advanced behavioral monitoring \cite{Otal2024}, and the ability to detect AI-powered attack vectors including autonomous LLM-based hacking agents \cite{reworr2024}. Recent research has demonstrated that AI-driven honeypots powered by Large Language Models can dynamically generate contextually appropriate, human-like responses in real-time, greatly improving their ability to deceive and engage attackers \cite{christli2024}.

However, while traditional honeypots suffer from limited interactivity and predictable behavior patterns that enable easy detection, existing research on AI-enhanced honeypots has yet to adequately address practical implementation frameworks, particularly for HTTP-based attack scenarios. The LLM in the Shell (SheLLM) project has shown promising results in creating generative honeypots for command-line interfaces \cite{sladic2023}, but comprehensive frameworks for web-based protocols remain underexplored.

This research addresses the gap between theoretical AI honeypot concepts and production-ready systems by developing and evaluating a deployable AI/LLM-enhanced honeypot specifically designed for HTTP protocol interactions. The primary research question guiding this study is: How can large language models be effectively integrated into HTTP honeypots to create more convincing, interactive decoy systems while maintaining operational feasibility for production environments?

The related work section examines various approaches to AI honeypot implementations, including model training methodologies for cybersecurity applications \cite{gizzarelli2024}, the integration of model-context protocols (MCP) in honeypot architectures, and threat mitigation strategies. Additionally, it explores containerized deployment approaches using Docker and analyzes how open-source developments in this field diverge from current academic research efforts.

The methodology section details the tools and frameworks employed in developing the honeypot system, establishing baseline requirements for cost-effectiveness, infrastructure needs, and performance expectations. Particular attention is given to the trade-offs between AI model sophistication and operational constraints, drawing insights from recent advances in test-time scaling for language models \cite{muennighoff2025}.

The results section presents implementation challenges and key discoveries, while addressing critical ethical and technical considerations inherent in honeypot deployment. This includes discussion of legal compliance, data privacy concerns, and responsible disclosure practices, particularly important given the sophisticated deception capabilities of AI-enhanced systems \cite{spitzner2003}.

The ability to quickly and accurately interpret data from security systems is paramount in the ever-evolving cybersecurity landscape. To enhance the effectiveness of honeypots, this research incorporates automatic mapping of collected logs to the MITRE ATT\&CK framework, a comprehensive and widely recognized knowledge base of adversary tactics and techniques \cite{gizzarelli2024}. By making this mapping process dynamic, security teams can immediately contextualize the activities observed in honeypot logs, identifying specific attack patterns and understanding the broader strategy behind intrusion attempts.

This thesis contributes to the field by implementing a production-ready AI/LLM honeypot for HTTP protocol interactions, capable of mimicking authentic web services, intelligently analyzing incoming requests, generating contextually appropriate responses, and maintaining response consistency through intelligent caching mechanisms. The convergence of AI-driven dynamic honeypots with automatic log mapping to frameworks like MITRE ATT\&CK represents a new era of evolved cybersecurity, where complex systems can grow by integrating generative AI into honeypots, creating interactions that challenge even the most experienced attackers \cite{gizzarelli2024}.



